#  TextClassification

Η εκφώνηση της εργασίας βρισκεται στο αρχείο `Β' Μέρος Εξαμηνιαία Εργασία Εφαρμοσμένης Επιστήμης Δεδομένων.pdf`

## B1.
Στο πλαίσιο του ερωτήματος B1, υλοποίησα ταξινομητές για την κατηγοριοποίηση
ελληνικών νομικών εγγράφων με χρήση διαφορετικών αναπαραστάσεων κειμένου και
αλγορίθμων επιβλεπόμενης μάθησης. Πραγματοποιήθηκε αρχική προεπεξεργασία
των κειμένων, με καθαρισμό από αριθμούς, σημεία στίξης και κεφαλαία γράμματα.
Επίσης, απομακρύνθηκαν οι ετικέτες που εμφανίζονταν λιγότερες από 5 φορές, ώστε
να διασφαλιστεί ότι το μοντέλο δεν θα εκπαιδευτεί σε μη αντιπροσωπευτικές ή
ασταθείς κατηγορίες.
Ως αρχικό σημείο αναφοράς χρησιμοποίησα έναν **dummy ταξινομητή**, ο οποίος
προβλέπει πάντοτε την πιο συχνή κατηγορία. Με αυτόν τον τρόπο δημιουργήθηκε
ένα βασικό επίπεδο απόδοσης (baseline), το οποίο επέτρεψε τη σύγκριση και την
αξιολόγηση της αποτελεσματικότητας των υπολοίπων μοντέλων. Όλα τα μοντέλα που
εκπαιδεύτηκαν ξεπέρασαν ξεκάθαρα την απόδοση του dummy, αποδεικνύοντας την
προστιθέμενη αξία των κατάλληλων τεχνικών αναπαράστασης και επιλογής
αλγορίθμου.
Για την επιλογή των υπερπαραμέτρων των μοντέλων, χρησιμοποίησα την τεχνική
**GridSearchCV**, η οποία εξετάζει όλους τους πιθανούς συνδυασμούς παραμέτρων σε
καθορισμένο εύρος τιμών και επιλέγει αυτόν που αποδίδει καλύτερα στο validation
set. Ως μετρική αξιολόγησης κατά το grid search χρησιμοποιήθηκε η **F1-score
(macro)**, καθώς πρόκειται για πρόβλημα πολυκατηγορικής ταξινόμησης με
ανισόρροπες κλάσεις. Η macro εκδοχή του F1-score δίνει ίσο βάρος σε κάθε
κατηγορία, ανεξαρτήτως συχνότητας, προσφέροντας έτσι μια πιο δίκαιη συνολική
εκτίμηση της απόδοσης του μοντέλου.

### Στο B1.i χρησιμοποίησα SVM με BoW και TF-IDF, η αναπαράσταση με TF-IDF
οδήγησε σε καλύτερα αποτελέσματα σε σχέση με το BoW, προσφέροντας
μεγαλύτερη διακριτική ικανότητα στο μοντέλο.
### Στο B1.ii, συνδύασα Logistic Regression με Word2Vec embeddings. Επέλεξα
Word2Vec επειδή παρέχει σημασιολογικά πλούσιες αναπαραστάσεις των λέξεων,
επιτρέποντας στο μοντέλο να αναγνωρίσει τη συνάφεια λέξεων με παρόμοιο νόημα.
### Στο B1.iii επέλεξα Naive Bayes με TF-IDF, καθώς αποτελεί απλή αλλά
αποτελεσματική μέθοδο για ταξινόμηση κειμένου. Το μοντέλο είχε ικανοποιητικά
αποτελέσματα και ξεπέρασε σημαντικά τον dummy ταξινομητή.

Όλα τα μοντέλα που υλοποιήθηκαν παρουσίασαν σαφώς καλύτερη απόδοση από τον
dummy ταξινομητή, επιβεβαιώνοντας την αποτελεσματικότητα των τεχνικών που
εφαρμόστηκαν. Ο SVM με TF-IDF σημείωσε την καλύτερη συνολική απόδοση, ειδικά
σε κατηγορίες με μεγαλύτερη συχνότητα. Το Logistic Regression με Word2Vec είχε
καλή συμπεριφορά σε πιο σύνθετες ή σπάνιες κατηγορίες, χάρη στη σημασιολογική
πληροφορία των embeddings. Το Naive Bayes με TF-IDF, παρότι απλό, πέτυχε
σταθερή και ανταγωνιστική απόδοση, λειτουργώντας ως ένα αξιόπιστο baseline.

# B2.
Η ανάλυση θεμάτων νομικών αποφάσεων του Αρείου Πάγου βασίστηκε στο dataset
Greek Legal Sum. Ως πρώτο βήμα, έγινε προκαταρκτική επεξεργασία του κειμένου:
αφαιρέθηκαν αριθμοί, σημεία στίξης και κεφαλαία γράμματα, ενώ χρησιμοποιήθηκε
λίστα ελληνικών stopwords (λέξεις χωρίς σημασιολογικό βάρος) για τον καθαρισμό
των κειμένων των αποφάσεων. Αυτή η διαδικασία βελτίωσε την ποιότητα της
αναπαράστασης κειμένου για την επόμενη ανάλυση.
## I. Εξερευνητική Ανάλυση (EDA)
Πραγματοποιήθηκε στατιστική διερεύνηση των πεδίων case_tags και case_category.
Με χρήση γραφημάτων συχνοτήτων αποτυπώθηκε η κυριαρχία συγκεκριμένων
θεματικών, όπως η “Αιτιολογίας επάρκεια” (με πάνω από 2.250 εμφανίσεις), η
“Νόμου εφαρμογή και ερμηνεία” και η “Ακυρότητα απόλυτη”. Παρατηρήθηκε
σημαντική συγκέντρωση σε λίγες ετικέτες, γεγονός που υποδηλώνει θεματική
πόλωση των αποφάσεων. Επίσης, μελετήθηκε η κατανομή του πλήθους ετικετών ανά
απόφαση, αποκαλύπτοντας ότι οι περισσότερες αποφάσεις περιέχουν 1–3 θεματικές.
## II. Ομαδοποίηση με K-means Clustering
Πριν την ομαδοποίηση, εφαρμόστηκε φιλτράρισμα στο dataset για αύξηση της
σημασιολογικής πυκνότητας των εγγραφών: κρατήθηκαν μόνο οι αποφάσεις που
διέθεταν πάνω από 5 μοναδικές κατηγορίες (case_category) και πάνω από 5 ετικέτες
(case_tags). Αυτό βοήθησε στην εστίαση της ανάλυσης σε κείμενα με πλουσιότερο
θεματικό περιεχόμενο. Για την αναπαράσταση των καθαρών κειμένων, δοκιμάστηκαν
διάφορες τεχνικές embeddings με κοινό preprocessing. Έγινε **αξιολόγηση με SVM**
ταξινομητή και διαπιστώθηκε ότι η TF-IDF αναπαράσταση προσέφερε τις καλύτερες
επιδόσεις , έτσι επιλέχθηκε ως βάση για την ομαδοποίηση. Στη συνέχεια
εφαρμόστηκε αλγόριθμος K-means για εύρος τιμών του K (2 -28). Η επιλογή του
βέλτιστου αριθμού συστάδων έγινε με βάση:
- το **Silhouette Score** (σε επίπεδο micro και macro),
- και το **Normalized Mutual Information (NMI)**, με στόχο την ευθυγράμμιση
των συστάδων με τις ετικέτες και κατηγορίες των αποφάσεων.
Τα αποτελέσματα αξιολόγησης έδειξαν ότι οι τιμές **K = 21 και K = 25** εμφάνισαν
υψηλές επιδόσεις τόσο σε Silhouette Score όσο και σε NMI. Ωστόσο, μετά από
οπτικοποίηση των συστάδων, διαπιστώθηκε ότι το **K = 21** προσφέρει τoν καλύτερo
διαχωρισιμό μεταξύ διαφορετικών συστάδων, και επομένως επιλέχθηκε ως η
βέλτιστη τιμή.
III. Εξαγωγή Τίτλων με LLM
Για κάθε συστάδα, επιλέχθηκαν τρεις αποφάσεις (είτε τυχαίες είτε κοντά στο
κεντροειδές) και στάλθηκαν ως prompt σε LLM (Llama-Krikri-8B-Instruct) μέσω της
βιβλιοθήκης Unsloth. Χρησιμοποιήθηκε ένα απλό, ενιαίο prompt την εκπαίδευση του
μοντέλου. Το μοντέλο παρήγαγε συνοπτικό τίτλο/θέμα για κάθε συστάδα, βάσει του
περιεχομένου των επιλεγμένων αποφάσεων. Η εξαγωγή του τίτλου έγινε με χρήση
κανονικών εκφράσεων (regular expressions) μέσω της συνάρτησης
extract_main_theme, η οποία αναζητούσε φράσεις που ξεκινούσαν με “Θέμα:”. Το
αποτέλεσμα καθαριζόταν από θόρυβο και ελέγχετο για ασάφεια ή υπερβολική
γενικότητα (π.χ. “αναιρεσίβλητος”, “αγωγή”).